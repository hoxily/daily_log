2020年12月17日，星期四，杭州

在百度首页打开DevTools，可以在Console里看到它们的招聘广告。里面的宣传文字好像更新了，成了现在这段：
“
每一个星球都有一个驱动核心，
每一种思想都有影响力的种子。
感受世界的温度，
年轻的你也能成为改变世界的动力，
百度珍惜你所有的潜力。
你的潜力，是改变世界的动力！
”

查看GLSL函数手册，比如 https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/clamp.xhtml 这里的clamp函数，总是会遇到奇奇怪怪的参数类型：genType, genIType, genUType, genDType。

其实在GLSLangSpec 4.40里的第8章 Built-in Functions有解释。

float, vec2, vec3, vec4 统一用 genType 代替；
int, ivec2, ivec3, ivec4 统一用 genIType 代替；
uint, uvec2, uvec3, uvec4 统一用 genUType 代替；
bool, bvec2, bvec3, bvec4 统一用 genBType 代替；
double, dvec2, dvec3, dvec4 统一用 genDType 代替；

另外，mat 对应于任意维度的单精度矩阵；dmat 对应于任意维度双精度矩阵。

----

折腾了一下在现有的lib_webgl项目上，针对baseColor类型的纹理，遇到png时仅变换到预乘alpha状态，而不还原回非预乘alpha状态，直接在shader里处理。

昨天已经试过了除以alpha分量来还原rgb分量，但是会出现神奇的白边。从原理上证明了，若想要进行PBR光照计算，只能将预乘alpha的纹理颜色还原回非预乘状态。

今天抛开还原的问题。仅针对找到的PMA介绍文章里的Blend公式做验证。也就是正常的
color = Src_rgb * Src_a + Dst_rgb * (1 - Src_a)
模式，因为纹理已经乘上了Src_a，所以Blend公式变成如下所示的计算过程：
color = Src_rgb + Dst_rgb * (1 - Src_a)

只需修改Style3DDecalMaterial构造函数，添加如下参数：
blendDst: THREE.OneMinusSrcAlphaFactor,
blendSrc: THREE.OneFactor,
blending: THREE.CustomBlending // 必需要设置blending为CustomBlending，才能使上面的这两项生效。

测试结果很奇怪依然有白边。找到很久，发现canvas画出的framebuffer变得透明了，透出来了canvas所在的div的background-color（也就是白色）。
于是又添加了两个控制Alpha的Blend系数：
blendDstAlpha: THREE.OneFactor,
blendSrcAlpha: THREE.ZeroFactor，
这两个系数的意图是让印花底下的面料写入的alpha保持为原先的1.0，然后印花片元输出的alpha乘上0相当于忽略掉。
但是结果还是很奇怪，出现了白边。还有更加神奇的地方。当把这个叠在面料上会出现白边的印花，拖到另一个印花上时，会发现边缘的白边接近消失。就像是已经画过一遍印花的地方，不会再透出白色来一样。

----

21点左右，罗元雷找我谈话，询问我对引擎方向的研究兴趣。大概是今下午15:00，罗元雷分享的性能优化ppt结束后，骆立康找他谈话的缘故。

总的意思就是，为了实现最终所需的性能与渲染效果，当前的基于threejs的框架肯定会大改，改得面目所非。甚至在这上面反而束手束脚。虽然罗元雷本身就已经有掌握在手里的现成引擎，但是直接拿来用也是个问题。

兴趣虽有，但是谈不上强烈。我最初使用Unity3D仅仅是想做游戏罢了。但是既然现在也没有在做游戏，连我自己都不知道我想要什么了。

另外他所说我有求知欲，其实我是不够的，并非如他口中所言那么钻研。所以相当汗颜。我在移植Qt QImage缩放图像的代码的时候，其实只是耐着性子将C++代码翻译成了typescript，并没有深入研究其中具体原理，位运算原理等。

我本可以更加深入的研究，但是却因为困难而半途而废。好像很多次人生中的重大选择，我都这么选的？选择一个自己感觉简单的选项。

他给了一个入手的点，从研究Google filament开始。

他希望团队中有更多懂引擎的人员。不会因为双方认知上的差距，有沟通上的难点。

他让我好好考虑。但是，正如我在咿呀游那边，咿呀游老板让我好好考虑那样，我却思考得不深，浮于表面。

我到底需要考虑什么东西？为什么感觉思考得没有深度？

----

目前影响我的一个缺点：缺乏深入研究的好奇心
    当前结果
        当前扒取的代码虽然已经可以工作，但是我没有深入研究它的原理。只是简单地抄了一遍。
    已知的疑惑点
        Qt里对预乘Alpha和非预乘Alpha的计算使用了难以理解的位运算。而不是常规的rgba / 255 的规一化方式，也不是Cocos里的(rgba+1) / 256
            它的qPremultiply和qUnpremultiply的计算原理
        QImageScaleInfo里的xapoints和yapoints的计算原理，包括它们的计算，以及在最终的4种缩放里的使用方式。为什么这玩意儿能抗锯齿？
            为什么有些情况下apoints只有0~256之间，有些情况下apoints大到9亿多？
        QImageScaleInfo里的xpoints与ypoints在总体上是反向索引原始图片的像素元素的下标。但是为什么会略有偏差？里面的位运算到底在搞什么？
        为了方便我选取了里面不含SSE4、ARM NEON加速指令的版本。SSE4、ARM NEON加速指令版本到底在干什么？为什么能加速？
        既然难以理解Qt的位运算，而javascript的位运算又只有32位有符号整数，如何确保移植的代码的正确性？
            srcWidth, srcHeight, destWidth, destHeight在哪个范围内，我移植的代码可以保证正确性？
                是可以在int32范围内的宽高都正常吗？

这样一一列出，感觉现在的移植版TextureScale.ts简单就是渣渣。能用却不懂其原理，边界条件也不清楚，什么时候会溢出也不知道。怎么可以仅仅凭感觉来。如果出bug了，我要怎么定位问题？
